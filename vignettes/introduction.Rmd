---
title: "Introduction"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>", 
  fig.align = "center",
  strip.white=TRUE,
  fig.env = "figure"
)

```
## `recolorize`: color-based image segmentation (for people with other things to do)

```{r, echo=FALSE, message=FALSE, fig.width = 5, fig.cap="`recolorize` output for *Chrysochroa corbetti*. Image credit: Nathan P. Lord."}
# bookkeeping
library(recolorize)
images <- dir(system.file("extdata/", package = "recolorize"), "png", full.names = TRUE)
img <- readImage(images[2])

# get fit
init_fit <- recolorize(img, plotting = FALSE)
re_fit <- recluster(init_fit, similarity_cutoff = 45, 
                    plot_hclust = FALSE,
                    plot_final = FALSE)

# plot it
layout(matrix(1:3, nrow = 1), widths = c(0.45, 0.1, 0.45))
par(mar = c(0, 0, 2, 0))
plotImageArray(re_fit$original_img, main = "Original")
plotColorPalette(re_fit$centers, re_fit$sizes, horiz = FALSE)
plotImageArray(re_fit$recolored_img, main = "Color map")
```

The `recolorize` package makes color maps, essentially color-based image segmentation, using a variety of automatic and semi-automatic procedures. If you want to measure almost anything about pattern and distribution of color in a set of images, you will probably want to start color maps; they let you discard the noise in an image while retaining information. The map above, for example, was generated using two functions and required only one user input parameter (`similarity_cutoff = 45`):

```{r, eval=F}
# get the path to the image (comes with the package, so we use system.file):
img <- system.file("extdata/corbetti.png", package = "recolorize")

# perform initial clustering:
init_fit <- recolorize(img)

# and refine:
re_fit <- recluster(init_fit, similarity_cutoff = 45)
```

Notice what we didn't have to input: we didn't have to declare how many colors we expected (5), what we expect those colors to be (red, green, blue, black, and white), which pixels to include in each color patch, or where the boundaries of those patches are. This color map allows to measure a number of things about the color and pattern of this beetle, such as how evenly distributed the colors are, the shapes and sizes of the different color patches, and where they fall on the body. 

```{r, echo=FALSE, fig.width = 7}
layout(matrix(1:5, nrow = 1))
layers <- splitByColor(re_fit)
```

The goal of `recolorize` is to make this process as easy, repeatable, and transparent as possible. There's no set of universal parameters that will give you perfect segmentation results for every image, because images alone don't always contain all the relevant information: color variation due to poor lighting in one image could be just as distinct as color variation due to pattern striations in another. So rather than provide an all-purpose black box, this package contains a handful of automatic, semi-automatic, and manual methods of generating these color maps. You should be able to generate pretty good color maps using the automatic and semi-automatic methods, and if necessary, be able to refine them using some manual steps that can still all be packaged in a single script and shared with others, no hand-waving required. This introduction will walk you through a few of those steps/functions, and hopefully enable you to apply these package functions to your own sets of images.

### Overview of package functions

The functions in `recolorize` fall into six categories:

1. Functions that load and/or minimally process an image (`loadImage`, `blurImage`, more soon).

2. Functions that do the initial color clustering on the original image (`recolorize`, `imposeColors`).

3. Functions that automatically edit the initial clustering results, i.e. refine an initial fit with few or no user-specified parameters (`recluster`, `thresholdRecolor`, `wernerColor`).

4. Functions that allow users to make manual-ish changes by taking user-specified parameters (`editLayers`, `mergeLayers`).

5. Functions for assessing the color fit or otherwise examining output (`colorResiduals`, `imDist`, `imHeatmap`, `plotColorPalette`, `plotImageArray`, `splitByColor`).

6. Functions to export to other packages (`recolorize_adjacency`, `constructImage`, `splitByColor`).

Depending on your images and goal, you probably won't need all of these. This vignette will demonstrate the functions in each category briefly, give a slightly wordier explanation of the major steps, then give a bit of .

## Quick start

1. Acquire white-balanced and decently lit images with transparent backgrounds.

2. Over-cluster an image (preferably with a transparent background) using `recolorize`, selecting a color space and a number of bins:
```{r, fig.width = 5}
# image path
corbetti <- system.file("extdata/corbetti.png", package = "recolorize")

# using default settings
init_fit <- recolorize(corbetti, method = "histogram", bins = 2, color_space = "sRGB")
```

3. Use an automatic method for reducing the number of clusters based on color similarity:
```{r, fig.width = 5}
# combine any colors whose CIE Lab Euclidean pairwise distance is < 45
recluster_fit <- recluster(init_fit, color_space = "Lab", similarity_cutoff = 45, plot_hclust = TRUE)
```

Or by trimming out minor colors:

```{r, fig.width = 5}
# this isn't as effective for the example image since it's too colorful, but for
# certain images it's really helpful!
threshold_fit <- thresholdRecolor(init_fit, pct = 0.05)
```

4. You can also make manual changes like merging and cleaning layers:
```{r, fig.width = 5}
# merge_list is a list of color indices to merge - this merges 3 & 5 (red/pink),
# 4 & 7 (green), 6 & 8 (blue)
merge_fit <- mergeLayers(init_fit, merge_list = list(1, 2, 
                                                     c(3, 5),
                                                     c(4, 7),
                                                     c(6, 8)))

# we can clean/despeckle layers:
edited_fit_clean <- editLayer(merge_fit, layer_idx = 1, operation = "clean", px_size = 2)
edited_fit_fill <- editLayer(merge_fit, layer_idx = 1, operation = "fill", px_size = 2)

# we can do several layers at once (and get a faux Mondrian for our trouble):
edited_multiple <- editLayers(merge_fit, operations = "clean", px_sizes = 10)
```
Or impose colors from one image onto another:

```{r, fig.width = 5}
im1 <- system.file("extdata/ocellata.png", package = "recolorize")
im2 <- system.file("extdata/ephippigera.png", package = "recolorize")

fit_1 <- recolorize(im1)
fit_2 <- imposeColors(im2, centers = fit_1$centers, adjust_centers = FALSE) 

# get RGB extremes:
rgb_centers <- t(col2rgb(c("red", "green", "blue", 
                         "cyan", "magenta", "yellow",
                         "black", "white")) / 255)
fit_rgb <- imposeColors(im2, centers = rgb_centers, adjust_centers = FALSE) # hm
```

5. Assess the color fit by plotting it in a few ways:
```{r, fig.width = 5}
# we can identify the hotspots of differences between two clustering methods:
fit_dist <- imDist(merge_fit$recolored_img, 
       recluster_fit$recolored_img)

# or between the original image and the color map:
im_dist <- imDist(merge_fit$original_img,
                  merge_fit$recolored_img)

# we can see how our residuals are distributed:
hist(im_dist, xlab = "CIE Lab distances")

# and we can split by color
layout(matrix(1:5, nrow = 1))
layers <- splitByColor(merge_fit, plot_method = "binary")
```

6. Finally, we can export a number of things:
```{r, eval=F}
# save the recolored image as an image
png::writePNG(recluster_fit$recolored_img)

# extract the layers and save them as individual binary masks:
layers <- splitLayers(recluster_fit)
for (i in 1:length(layers)) {
  png::writePNG(layers[[i]], target = paste0("layer_", i, ".png"))
}

# generate a 'classify' obj and run an adjacency analysis in pavo
classify_obj <- classify_recolorize(recluster_fit)
adjacency_result <- pavo::adjacent(classify_obj, xscale = 10)
```

# Image preparation

Before we attempt image segmentation, we need segmentable images. `recolorize` doesn't process your images for you beyond a few basic things like resizing, rotating, and blurring (which can help with segmentation). You should do all image processing steps which are usually necessary for getting quantitative color data, like white balance correction, gradient correction, or background removal, before inputting them to `recolorize`. 

There are lots of software tools available for making these kinds of corrections: [GIMP](https://www.gimp.org/), [FIJI/ImageJ](https://imagej.net/Fiji), and even the [imager](https://dahtah.github.io/imager/) package will provide options for some or all of these. If you really want to get pipeline-y, Python has a much more robust set of image processing libraries that will help with automatic color correction and background masking, which is well beyond the scope of this intro. If you are at all concerned with sensory biology and animal vision, we highly recommend [micaToolbox](http://www.empiricalimaging.com/knowledge-base/), which is a well-documented and comprehensive toolkit for creating images as animals see them (rather than as cameras and computers see them); see especially the instructions for creating false color [cone-mapped images](http://www.empiricalimaging.com/knowledge-base/creating-cone-catch-models/).

The corrections you have to make really depend on what you're trying to do. If you just care about the regions but don't really care about the final colors they end up being assigned, you probably don't need to worry too much about color correction; if you're working with histology slides, you probably don't need to mask the background; if you have a really even and diffuse lighting setup, you probably won't have to deal with shadows or gradients.

### Background masking with transparencies

If you're masking the background, use transparencies. This is pretty easy to do in GIMP, Photoshop, or ImageJ. The transparency layer (or alpha channel) is the fourth channel of an image (the other three being the R, G, and B channels), and `recolorize` treats it like a binary mask: any pixel with an alpha value of 1 is retained, and any pixel with an alpha value of < 1 is ignored. This means you don't have to worry about finding a uniform background color that is sufficiently different from your foreground object in every image, which can otherwise be a real pain. Using transparency is unambiguous, and has the bonus benefit of making for nicer plots, too, since you don't have to worry about the corners of your images overlapping and blocking each other. All the images in this demo have transparent backgrounds. However, you can use the `lower` and `upper` arguments to set boundaries for excluding pixels as background based on their color (see documentation). Just know that these will be set to transparent internally.

# Loading images

We can read in an image by passing the filepath to the `readImage` function.

```{r}
# define image path - we're using an image that comes with the package
img_path <- system.file("extdata/corbetti.png", package = "recolorize")

# load image
img <- readImage(img_path)

# it's just an array with 4 channels:
dim(img)
```

An image is a numeric array with either 3 or 4 channels (R, G, B, and optionally alpha for transparency). JPG images will only have 3 channels; PNG images will have 4. This is quite a small image (243x116 pixels) with 4 channels.

We can plot the whole array as an image, or plot one channel at a time:
```{r, fig.width = 7}
layout(matrix(1:5, nrow = 1))
plotImageArray(img, main = "RGB image")
plotImageArray(img[ , , 1], main = "R channel")
plotImageArray(img[ , , 2], main = "G channel")
plotImageArray(img[ , , 3], main = "B channel")
plotImageArray(img[ , , 4], main = "Alpha channel")
```

Most of the `recolorize` functions that work with original images will take an image path as an argument and call on this function, in which case you'll never need to call it directly. But it's helpful to understand that this is how R handles images.

The only other function currently in this category is `blurImage`, which is essentially just a wrapper for the various blur functions in the `imager` package. This is especially useful for color segmentation on organisms, because it can help to reduce color variation due to texture (scales, ridges, reflection, etc), so if you find that you're having a lot of those sorts of problems, it might be worth it to try out some of the blurring options. We'll use this later in the examples to deal with a particularly shiny beetle picture, for example.


# Initial clustering

The color clustering in `recolorize` usually starts with an initial clustering step which produces more color clusters than the final color map will have, which are then edited and combined to form the final color map. We start with an over-clustering step because it is a quick way to go from an overwhelming number of colors (256^3 unique RGB colors) to a manageable number that can be manually inspected or automatically re-clustered. You'll usually do this using the `recolorize` function, which is the core of the package (go figure!):

```{r}
corbetti <- system.file("extdata/corbetti.png", package = "recolorize")

# using all the default parameters:
recolorize_defaults <- recolorize(img = corbetti)

# you can also read in the image as an array:
corbetti_array <- readImage(corbetti)

# and then pass it to the recolorize function 
# (not plotting this time since it gives you identical results)
recolorize_defaults <- recolorize(img = corbetti_array, plotting = FALSE)
```

This function returns an object of class `recolorize`, a list with several elements:

```{r}
class(recolorize_defaults)
attributes(recolorize_defaults)
summary(recolorize_defaults)
```

Before we head into the next step, it's helpful to unpack exactly what this class contains, since most of the other functions in this package will draw on these elements. 

`original_img` and `recolored_img` are pretty much what you'd expect: image arrays like the one we got from `readImage`, one for the original image (leftmost panel in the plot above) and one for the recolored one (middle panel). They will always be the same size. 

`method` is a list describing the recoloring method, both the clustering approach and the number of bins specified. `color_space` is the name of the color space in which we did the clustering. 

`centers` is a 3-column RGB matrix of the color centers for each cluster, one row per color-- a pure white center would correspond to a row of `(1, 1, 1)`, for example (RGB colors in R mostly operate on a 0-1 scale, rather than 0-255). `sizes` is a vector of cluster sizes, measured as the number of non-background pixels assigned to that color; its order matches that of the `centers` matrix. 

Finally, `pixel_assignments` is a matrix of which pixel got assigned to which cluster; it's essentially a paint-by-numbers array. All background pixels get assigned a 0, all pixels assigned to cluster 1 have a 1, etc. Notice that it has the same number of rows and columns as the image arrays, but only one layer:

```{r}
dim(recolorize_defaults$recolored_img)
dim(recolorize_defaults$pixel_assignments)
```

All you need to create a color map is this pixel assignment matrix and the color centers matrix, since we can use the pixel assignments to generate a color image. That's what the `constructImage` function does:

```{r, fig.width=4, fig.asp = 0.8}
# using just the pixel_assignments and centers to recreate the recolored image:
recolored_img <- constructImage(pixel_assignments = recolorize_defaults$pixel_assignments, 
                                centers = recolorize_defaults$centers)

# we can also pass a different set of centers:
new_centers <- viridisLite::viridis(8)
new_centers <- t(col2rgb(new_centers) / 255)
viridis_img <- constructImage(pixel_assignments = recolorize_defaults$pixel_assignments, 
                                centers = new_centers)

layout(matrix(1:2, nrow = 1))
plotImageArray(recolored_img, main = "recolored image")
plotImageArray(viridis_img, main = "swapped centers")
```

You can also inspect the color palette on its own:

```{r, fig.asp=0.25, fig.width = 5}
# where we're going, we don't need figure margins!
par(mar = rep(0, 4))

# all colors the same size, with printed numbers for their index
plotColorPalette(centers = recolorize_defaults$centers)

# colors proportional to their region size in the image
plotColorPalette(centers = recolorize_defaults$centers, 
                 sizes = recolorize_defaults$sizes)
```

### Clustering parameters

If you look at the documentation for the `recolorize` function, you'll see a lot of user-specifiable parameters. There are only really 3 major ones:

1. The clustering method (`method` argument)
2. The number of color clusters (`bins` and `n`)
3. The color space (`color_space`)

That said, the defaults work pretty well in most cases, and so long as you can see that you're not mushing together regions that should remain separate, most parameter combinations will work. 

#### Clustering methods and number of color clusters

The two clustering methods in `recolorize` are color histogram binning (fast, consistent, and deterministic) and k-means clustering (comparatively slower and heuristic, but more intuitive). The `bins` argument is accessed by the `histogram` method, and `n` goes with the `kmeans` method. I highly recommend the histogram binning unless you have a good reason not to use it, but we'll go over them both. Before I explain them, let's do a quick comparison:

```{r, fig.height = 3}
# number of bins is ^3, so we'll specify 2 bins and 8 kmeans clusters to get 8 color centers either way:
hist_obj <- recolorize(corbetti, method = "histogram", bins = 2)
kmeans_obj <- recolorize(corbetti, method = "kmeans", n = 8)
```

For this image, both of these options do a pretty decent job at simplifying the image down to 8 colors, but there are substantial differences in their approaches.

To understand the differences, it helps to start by looking at all the pixels in the original image in a given color space. We'll use RGB for now, since most people are familiar with it:
```{r,message=FALSE, fig.width = 7, fig.height = 3}
# plot the pixels in the image in RGB color space:
library(colordistance)

layout(matrix(1:2, nrow = 1))
plotPixels(corbetti, angle = 30, main = "",
           cex.lab = 0.5, cex.axis = 0.5,
           mar = rep(2, 4))
plotPixels(corbetti, angle = -30, main = "", 
           cex.lab = 0.5, cex.axis = 0.5,
           mar = rep(2, 4))
```
Each location represents a different color. So this step takes us from an overwhelming number of unique colors to just a few.

Histogram binning divides up this 3D color space into bins, then counts the number of pixels that fall into that bin and calculates their average color. The nice thing about this is that it's quite fast, since we're not really doing any clustering; the bins we assign the pixels to will be the same for every image, and we're not calculating the distances between the pixels and their assigned color. We're just checking which pixels fall into which region. The *really* nice thing is that it's deterministic, which means you get the same result every single time you run it. The downside is that makes this approach almost guaranteed to over-split colors, since your color regions will rarely fall cleanly within the boundaries of these bins, and many of the bins you end up with will be empty or have very few pixels. We can see this if we increase the number of bins per color channel:

```{r,message=FALSE, fig.width = 7.5, fig.height=3}
layout(matrix(1:3, nrow = 1))

# using increasing numbers of bins per channel:
for (i in 2:4) {
  hist_fit <- recolorize(corbetti, method = "hist", bins = i, plotting = FALSE)
  plotColorClusters(centers = hist_fit$centers, 
                    sizes = hist_fit$sizes, scaling = 10,
                    tick.marks = F, xlab = "R", ylab = "G", zlab = "B",
                    main = paste(i, "bins per channel"))
}
```

Notice a couple of things: first, the number of bins increases as the cube of the `bins` argument (so 2, 3, 4 = 8, 27, and 64 bins). That's because we're dividing each of the R, G, and B color channels into that many bins. Second, even as we increase the number of bins, most of those bins are staying empty (or very small). Even with 64 color centers, we still end up with a few large ones and many tiny ones:

```{r}
plot(hist_fit, sizes = TRUE)
```

K-means clustering, on the other hand, is a well-known method for partitioning data into *n* clusters. You just provide the number of clusters you want, and it will try to find the best locations for them, where 'best' means minimizing the squared Euclidean distances between pixels and color centers within each cluster. A lot of color segmentation tools will *only* use k-means clustering (or a similar method), because it's relatively easy to implement and does produce good results if your images have clear color boundaries and very different colors (i.e. the pixels are far apart in color space). If you were going to stop at the initial clustering step, this would probably be a better option than the histogram binning for that reason. One issue if you're trying to process many images, though, is that you have to decide how many clusters you want for each one, and there's no clear criterion for selecting that value:

```{r, fig.width=7.5, fig.height = 4}
k_vec <- 3:10
layout(matrix(1:8, nrow = 2))
for (i in k_vec) {
  kmeans_fit <- recolorize(corbetti, "k", n = i, plotting = FALSE)
  plotColorClusters(centers = kmeans_fit$centers, 
                    sizes = kmeans_fit$sizes, scaling = 10,
                    tick.marks = F,
                    xlab = "", ylab = "", zlab = "", 
                    main = paste("n =", i),
                    mar = c(2, 1, 2, 1),
                    xlim = 0:1, ylim = 0:1, zlim = 0:1)
}
```

But the main issue with this method is that it's implemented heuristically, which means you're not guaranteed to get the same results every time you run it; and although you should get similar ones, you'll also get the color centers returned to you in a random order. We can see this by running the exact same k-means clustering code 3 times:

```{r, fig.width = 6, fig.height = 4}
kmeans_1 <- recolorize(corbetti, method = "k", n = 8, plotting = FALSE)
kmeans_2 <- recolorize(corbetti, method = "k", n = 8, plotting = FALSE)
kmeans_3 <- recolorize(corbetti, method = "k", n = 8, plotting = FALSE)

layout(matrix(1:6, nrow = 1), widths = c(rep(.25, 3),
                                         rep(.25/3, 3)))
for (i in list(kmeans_1, kmeans_2, kmeans_3)) {
  par(mar = rep(0, 4))
  plotImageArray(i$recolored_img)
}
for (i in list(kmeans_1, kmeans_2, kmeans_3)) {
  par(mar = rep(0, 4))
  plotColorPalette(i$centers, i$sizes, horiz = FALSE)
}
```

The differences in the color maps are subtle (but noticeable), but notice especially the order of the colors in the color palettes on the right. More or less the same color centers pop up, but their index values don't match. If you run this code one day and pull out all the red clusters by their index, or merge the multiple green clusters, those values will change the next time you run the code. That and the need to specify cluster numbers for each image are more or less why I recommend not using this method unless you have a reason.

#### Color spaces

There is a lot to be said about color spaces, and most of it is complicated and requires a lot of math. The most common color space is RGB: this is how images are stored and displayed on most computers. Check out [this vignette](https://cran.r-project.org/web/packages/colordistance/vignettes/color-spaces.html) for a quick overview of why they matter for color clustering. Basically, a color space is a coordinate system with an agenda: some color spaces attempt to mimic human color vision, others are computationally simple, and others are useful for manipulating colors and palettes. We can convert between color spaces (sometimes with a bit of extra information), and most of them are three-dimensional, but the axes represent very different things.

For our purposes, that means that the color space you choose to do your clustering in can have profound effects on your results, because it determines the Euclidean distances between different colors. For example, in RGB space, red and yellow are as far apart from each other as red and black, but black and yellow are farther apart than black and red are. That doesn't really line up with our perception, but it's how the color space is arranged. CIE Lab color space is specifically designed to mimic human color perception (so the Euclidean distances reflect perceived distances), but it's also a weird blob shape, so we usually need more initial partitions to separate out the colors. We can try out different color spaces:

```{r, fig.width = 6, fig.height = 2.5}
rgb_fit <- recolorize(corbetti, color_space = "sRGB", plotting = FALSE)
lab_fit <- recolorize(corbetti, color_space = "Lab", plotting = FALSE)

layout(matrix(1:4, nrow = 1), widths = c(.4, .1, .4, .1))
par(mar = c(0, 2, 0, 0))
plotImageArray(rgb_fit$recolored_img, "RGB space")
plotColorPalette(rgb_fit$centers, rgb_fit$sizes)
plotImageArray(lab_fit$recolored_img, "CIE Lab space")
plotColorPalette(lab_fit$centers, lab_fit$sizes)
```

You may notice that for all I talked it up, the CIE Lab space option looks terrible. That's because unlike RGB space, CIE Lab colors aren't evenly distributed across a cube, so most of the different colors are in the center of the range. 2 bins per channel doesn't do a great job with splitting that up. We get much better results if we allow for more than 2 bins per channel:

```{r}
lab_fit_3 <- recolorize(corbetti, bins = 4, color_space = "Lab")
```

That said, I usually find myself using RGB space for the initial clustering step, and CIE Lab space for refining those results. One thing to note is that regardless of which color space you use for clustering, the `centers` matrix is *always in RGB color space*. That's because it's used for plotting. 

I don't have much general guidance for how to choose between all of these parameters at this stage; I would recommend using histogram binning in RGB space, with as many bins as needed to separate out all of the different colors. But part of the reason I'm including more options than that is because it really does depend on the color distribution in your images. This *Chrysochroa corbetti* image, for example, is literally red, green, and blue; that makes RGB space pretty appropriate for a first pass!  

It's convenient to use the same scheme for every image in your dataset, so you might end up using whatever values are needed for your most complex image and over-splitting most of your other images. That's usually fine, because the next set of steps will try to lump colors together or remove minor details. You want to be just granular enough to capture the details you care about, and it's okay if some colors are split up. 

### `imposeColors()`

Another option is to impose colors on an image, rather than using intrinsic image colors. Every pixel is assigned to the color it is closest to in some specified color space. Usually, this is useful for batch processing: you get colors from one image, then map them onto another image, so that the color centers correspond across all your images.

```{r, fig.width=5}
im1 <- system.file("extdata/ocellata.png", package = "recolorize")
im2 <- system.file("extdata/ephippigera.png", package = "recolorize")

fit1 <- recolorize(im1)
fit2 <- imposeColors(im2, centers = fit1$centers)
```



# Refining fits automatically and semi-automatically

Once we've reduced an image down to a tractable number of colors, we can define simple procedures for how to combine them based on similarity. `recolorize` (currently) comes with two of these: `recluster`, which merges colors by perceived similarity, and `thresholdRecolor`, which drops minor colors. Both are simple, but surprisingly effective. They're also built on top of some really simple functions we'll see in a bit, so if you need to, you can build out a similar procedure tailored to your dataset-- for example, combining layers based only on their brightness values, or only combining green layers.

### `recluster()`

This is the one I use the most often, and its implementation is really simple. This function calculates the Euclidean distances between all the color centers in a `recolorize` object, clusters them hierarchically using `hclust`, then uses a user-specified cutoff to combine the most similar colors. As with `recolorize`, you can choose your color space, and that will make a big difference. Let's see this in action:

```{r}
recluster_results <- recluster(recolorize_defaults, 
                               similarity_cutoff = 45)
```
Notice the color dendrogram: it lumped together clusters 4 & 7, clusters 3 & 5, and clusters 6 & 8, because their distance was less than 45. This is in CIE Lab space; if we use RGB space, the range of distances is 0-1:

```{r}
recluster_rgb <- recluster(recolorize_defaults, color_space = "sRGB",
                           similarity_cutoff = 0.5)
```

In this case, we get the same results, but this is always worth playing around with. There's also a lot of room for modification here: this is a pretty unsophisticated rule for combining color clusters (ignoring, for example, cluster size, proximity, geometry, and boundary strength), but it's pretty simple to write better rules if you can think of them. 

### `thresholdColor()`

An even simpler rule: drop the smallest color clusters whose cumulative sum (as a proportion of total pixels assigned) is lower than some threshold, like 5% of the image. I thought this would be too simple to be useful, but every once in a while it's just the thing, especially if you always end up with weird spurious details.

# 'Manual' edits

'Manual' edits are in scare quotes here because there's no pointing and clicking involved. There are currently only a handful of these, but I'm testing several more.

### `editLayers`

Applies basic morphological operations from the imager package to individual layers. You can edit any combination of layers with any combination of the four included morphological operations (clean, fill, grow, and shrink). This is useful for a few things; I've found it especially useful in dealing with specular reflections, where you'll end up with a little scattering of white or light 'color' on the shiniest parts of the organism, or in dealing with spurious pixels, as in the cream layer of the image we've been using:

```{r}
# edit a single layer
cream_edit <- editLayer(recluster_results, layer_idx = 2, operation = "clean", px_size = 3)

# edit multiple layers
mondrian <- editLayers(recluster_results, operations = "clean", px_sizes = 10)
```

This function is also easy to modify. Internally, it splits the color map into individual masks using `splitByColor()` (another `recolorize` function), then converts those to pixsets for use in `imager` before slotting them back in with the unchanged layers.  

### `mergeLayers`

Sometimes, you don't want to define fancy rules for deciding which layers to combine; you just want to combine layers. That's what this function is for. It takes in a list of numeric vectors for layers to combine (layers in the same vector are combined; those in different list elements are kept separate). 

```{r, fig.width=5}
merge_fit <- mergeLayers(recolorize_defaults, 
                         merge_list = list(1, 2, 
                                           c(3, 5),
                                           c(4, 7),
                                           c(6, 8)))
```

You might notice this is a bit different than our `recluster` results:

```{r, fig.width=5}
layout(matrix(1:2, 1))
plotImageArray(recluster_results$recolored_img, main = "recluster")
plotImageArray(merge_fit$recolored_img, main = "mergeLayers")
```

That's because internally, `recluster` actually uses `imposeColors` to refit the color map, rather than just merging layers; I have found this often produces slightly nicer results, because pixels that were on the border of one cutoff or another don't get stranded in the wrong layer.

# Assessing color fit

Making color maps is an obviously visual process, so it's good to use visual feedback as much as possible. You've already seen a few of these functions in action, specifically `plotColorPalette` and `plotImageArray`, which are used in almost every function that produces a recolorize object. I'll point out two others that I think are quite useful: `imDist` and `splitByColor`.

### `imDist()`

`imDist` finds the distances between two images and plots the resulting heatmap. You can use it to get the distances between the original image and the color map:

```{r}
dist_original <- imDist(recluster_results$original_img, 
                        recluster_results$recolored_img, color_space = "Lab")
```

Or you can use it to compare two fits:

```{r}
dist_fits <- imDist(merge_fit$recolored_img,
                    recluster_results$recolored_img, color_space = "Lab")
```

The resulting object is a simple matrix of distances between each pair of pixels in the given color space. 
These are essentially residuals:

```{r}
hist(dist_original, main = "CIE Lab residuals", xlab = "CIE Lab distance")
```
A word of warning here: it is easy to look at this and decide to come up with a procedure for automatically fitting color maps using a kind of AIC metric, trying to get the lowest SSE with the minimum set of color centers. You're welcome to try that, but given that this is discarding spatial information, it is probably not a general solution (I haven't had much luck with it). But there is probably some room to play here.

### `splitByColor()`

This is a dual-use function: by splitting up the color map into individual layers, you not only can examine the individual layers and decide whether they need any editing or merging, but you also get out a binary mask representing each layer, so you can export individual patches.

```{r}
layout(matrix(1:10, nrow = 2, byrow = TRUE))

# 'overlay' is not always the clearest option, but it is usually the prettiest:
layers <- splitByColor(recluster_results, plot_method = "overlay")

# layers is a list of matrices:
lapply(layers, plotImageArray)
```

# Exporting

A color map is only useful if you can actually use it for your analysis. The
most direct thing you can do is simply export your recolored images as images,
then pass those to whatever other tool you'd like to use, although obviously
this doesn't take full advantage of the format. I'm currently working on ways to export color patches
as SVGs, but for now you can export as raster using `writePNG`:

```{r, eval=F}
# export color map
png::writePNG(recluster_results$recolored_img,
              target = "recolored_corbetti.png")

# export individual layers from splitByColor
for (i in 1:length(layers)) {
  png::writePNG(layers[[i]],
                target = paste0("layer_", i, ".png"))
}

```

You can also convert a recolorize object to a `classify` object in the wonderful
`pavo` package and then run an adjacency analysis. Bonus points if you have 
reflectance spectra for each of your color patches: by combining the spatial
information in the color map with the `coldist` object generated by reflectance
data, you can run adjacency analysis for the visual system(s) of your choice
right out of the box!

```{r}
as_classify <- classify_recolorize(recluster_results, imgname = "corbetti")
adj_analysis <- pavo::adjacent(as_classify, xscale = 10)
```

You can also run an adjacency analysis with `recolorize_adjacency`, but only as long
as you keep your skeptic hat on. This function works by calculating a `coldist` object
right from the CIE Lab colors in the color maps, which are themselves probably derived
from your RGB image, which is at best a very loose representation of how these
colors appear to human eyes. The only reason this is at all reasonable is that it's 
producing these values for human vision, so you will be able to see if it's completely
unreasonable. This is fine for getting some preliminary results or if you're working
with aggregate data from many sources and you're content with specifically human (not just
non-UV, but only human) vision. Otherwise, it's probably a last resort.


# Some considerations

### This is a lot of options. How do I choose a procedure?

Most things will more or less work; if it looks reasonable, it is. Keep in mind
that there is a big difference between getting slightly different color maps and
getting qualitatively different results. Keep your final goal in mind. You can
also try lots of different things and see if it makes a real difference.

I wish I could write a single function that would do all of these steps in the
correct sequence and produce perfect results; the reason that function does not
exist is because I find I have to do experiment a fair amount with every image
set, and I often end up with a different order of operations depending on the 
problem. So I'll often end up defining a sort of meta-function 

### What if my parameters work well for some images, but not others?

This is almost certainly going to be the case, and there's not a simple
solution. I find that I tend to do the same batch processing for all of my
images (usually recolorize followed by recluster), then doing cleanup with the
'manual' edit functions on an image-by-image basis, and using `rlang::enexpr` to
tag the code I used to generate the color map onto the recolorize object itself
before saving it.

You can also get way fancier with cutoffs than I have here. This package is
built on some pretty simple scaffolding: you get a starting set of clusters,
then you modify them. If you have a better/more refined way of deciding which
colors to cluster, then go for it.

There is another very tempting option: make a small training set of nice color maps
manually with `recolorize`, then use those to either fit a statistical model for
other fits or use machine learning to do the rest.

