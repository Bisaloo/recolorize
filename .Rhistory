re_fit <- recluster(init_fit, similarity_cutoff = 45)
```
Notice what we didn't have to input: we didn't have to declare how many colors we expected (5), what we expect those colors to be (red, green, blue, black, and white), which pixels to include in each color patch, or where the boundaries of those patches are. This color map allows to measure a number of things about the color and pattern of this beetle, such as how evenly distributed the colors are, the shapes and sizes of the different color patches, and where they fall on the body.
```{r, echo=FALSE, fig.width = 7}
layout(matrix(1:5, nrow = 1))
layers <- splitByColor(re_fit)
```
The goal of `recolorize` is to make this process as easy, repeatable, and transparent as possible. There's no set of universal parameters that will give you perfect segmentation results for every image, because images alone don't always contain all the relevant information: color variation due to poor lighting in one image could be just as distinct as color variation due to pattern striations in another. So rather than provide an all-purpose black box, this package contains a handful of automatic, semi-automatic, and manual methods of generating these color maps. You should be able to generate pretty good color maps using the automatic and semi-automatic methods, and if necessary, be able to refine them using some manual steps that can still all be packaged in a single script and shared with others, no hand-waving required. This introduction will walk you through a few of those steps/functions, and hopefully enable you to apply these package functions to your own sets of images.
### Overview of package functions
The functions in `recolorize` fall into six categories:
1. Functions that load and/or minimally process an image (`loadImage`, `blurImage`, more soon).
2. Functions that do the initial color clustering on the original image (`recolorize`, `imposeColors`).
3. Functions that automatically edit the initial clustering results, i.e. refine an initial fit with few or no user-specified parameters (`recluster`, `thresholdRecolor`, `wernerColor`).
4. Functions that allow users to make manual-ish changes by taking user-specified parameters (`editLayers`, `mergeLayers`).
5. Functions for assessing the color fit or otherwise examining output (`colorResiduals`, `imDist`, `imHeatmap`, `plotColorPalette`, `plotImageArray`, `splitByColor`).
6. Functions to export to other packages (`recolorize_adjacency`, `constructImage`, `splitByColor`).
Depending on your images and goal, you probably won't need all of these. This vignette will demonstrates the functions in each category briefly, but then work through a couple of examples that string together a few of these functions to quickly produce results.
# Image preparation
Before we attempt image segmentation, we need segmentable images. `recolorize` doesn't process your images for you beyond a few basic things like resizing, rotating, and blurring (which can help with segmentation). You should do all image processing steps which are usually necessary for getting quantitative color data, like white balance correction, gradient correction, or background removal, before inputting them to `recolorize`.
There are lots of software tools available for making these kinds of corrections: [GIMP](https://www.gimp.org/), [FIJI/ImageJ](https://imagej.net/Fiji), and even the [imager](https://dahtah.github.io/imager/) package will provide options for some or all of these. If you really want to get pipeline-y, Python has a much more robust set of image processing libraries that will help with automatic color correction and background masking, which is well beyond the scope of this intro. If you are at all concerned with sensory biology and animal vision, we highly recommend [micaToolbox](http://www.empiricalimaging.com/knowledge-base/), which is a well-documented and comprehensive toolkit for creating images as animals see them (rather than as cameras and computers see them); see especially the instructions for creating false color [cone-mapped images](http://www.empiricalimaging.com/knowledge-base/creating-cone-catch-models/).
The corrections you have to make really depend on what you're trying to do. If you just care about the regions but don't really care about the final colors they end up being assigned, you probably don't need to worry too much about color correction; if you're working with histology slides, you probably don't need to mask the background; if you have a really even and diffuse lighting setup, you probably won't have to deal with shadows or gradients.
### Background masking with transparencies
If you want to mask the background, I highly recommend using transparencies. This is pretty easy to do in GIMP, Photoshop, or ImageJ. The transparency layer (or alpha channel) is the fourth channel of an image (the other three being the R, G, and B channels), and `recolorize` treats it like a binary mask: any pixel with an alpha value of 1 is retained, and any pixel with an alpha value of < 1 is ignored. This means you don't have to worry about finding a uniform background color that is sufficiently different from your foreground object in every image, which can otherwise be a real pain. Using transparency is unambiguous, and has the bonus benefit of making for nicer plots, too, since you don't have to worry about the corners of your images overlapping and blocking each other. All the images in this demo have transparent backgrounds.
# Loading images
We can read in an image by passing the filepath to the `readImage` function.
```{r}
# define image path - we're using an image that comes with the package
img_path <- system.file("extdata/corbetti.png", package = "recolorize")
# load image
img <- readImage(img_path)
# it's just an array with 4 channels:
dim(img)
```
An image is a numeric array with either 3 or 4 channels (R, G, B, and optionally alpha for transparency). JPG images will only have 3 channels; PNG images will have 4. This is quite a small image (243x116 pixels) with 4 channels.
We can plot the whole array as an image, or plot one channel at a time:
```{r, fig.width = 7}
layout(matrix(1:5, nrow = 1))
plotImageArray(img, main = "RGB image")
plotImageArray(img[ , , 1], main = "R channel")
plotImageArray(img[ , , 2], main = "G channel")
plotImageArray(img[ , , 3], main = "B channel")
plotImageArray(img[ , , 4], main = "Alpha channel")
```
Most of the `recolorize` functions that work with original images will take an image path as an argument and call on this function, in which case you'll never need to call it directly. But it's helpful to understand that this is how R handles images.
The only other function currently in this category is `blurImage`, which is essentially just a wrapper for the various blur functions in the `imager` package. This is especially useful for color segmentation on organisms, because it can help to reduce color variation due to texture (scales, ridges, reflection, etc), so if you find that you're having a lot of those sorts of problems, it might be worth it to try out some of the blurring options. We'll use this later in the examples to deal with a particularly shiny beetle picture, for example.
# Initial clustering
The color clustering in `recolorize` usually starts with an initial clustering step which produces more color clusters than the final color map will have, which are then edited and combined to form the final color map. We start with an over-clustering step because it is a quick way to go from an overwhelming number of colors (256^3 unique RGB colors) to a manageable number that can be manually inspected or automatically re-clustered. You'll usually do this using the `recolorize` function, which is the core of the package (go figure!):
```{r}
corbetti <- system.file("extdata/corbetti.png", package = "recolorize")
# using all the default parameters:
recolorize_defaults <- recolorize(img = corbetti)
# you can also read in the image as an array:
corbetti_array <- readImage(corbetti)
# and then pass it to the recolorize function
# (not plotting this time since it gives you identical results)
recolorize_defaults <- recolorize(img = corbetti_array, plotting = FALSE)
```
This function returns an object of class `recolorize`, a list with several elements:
```{r}
class(recolorize_defaults)
attributes(recolorize_defaults)
summary(recolorize_defaults)
```
Before we head into the next step, it's helpful to unpack exactly what this class contains, since most of the other functions in this package will draw on these elements.
`original_img` and `recolored_img` are pretty much what you'd expect: image arrays like the one we got from `readImage`, one for the original image (leftmost panel in the plot above) and one for the recolored one (middle panel). They will always be the same size.
`method` is a list describing the recoloring method, both the clustering approach and the number of bins specified. `color_space` is the name of the color space in which we did the clustering.
`centers` is a 3-column RGB matrix of the color centers for each cluster, one row per color-- a pure white center would correspond to a row of `(1, 1, 1)`, for example (RGB colors in R mostly operate on a 0-1 scale, rather than 0-255). `sizes` is a vector of cluster sizes, measured as the number of non-background pixels assigned to that color; its order matches that of the `centers` matrix.
Finally, `pixel_assignments` is a matrix of which pixel got assigned to which cluster; it's essentially a paint-by-numbers array. All background pixels get assigned a 0, all pixels assigned to cluster 1 have a 1, etc. Notice that it has the same number of rows and columns as the image arrays, but only one layer:
```{r}
dim(recolorize_defaults$recolored_img)
dim(recolorize_defaults$pixel_assignments)
```
All you need to create a color map is this pixel assignment matrix and the color centers matrix, since we can use the pixel assignments to generate a color image. That's what the `constructImage` function does:
```{r, fig.width=4, fig.asp = 0.8}
# using just the pixel_assignments and centers to recreate the recolored image:
recolored_img <- constructImage(pixel_assignments = recolorize_defaults$pixel_assignments,
centers = recolorize_defaults$centers)
# we can also pass a different set of centers:
new_centers <- viridisLite::viridis(8)
new_centers <- t(col2rgb(new_centers) / 255)
viridis_img <- constructImage(pixel_assignments = recolorize_defaults$pixel_assignments,
centers = new_centers)
layout(matrix(1:2, nrow = 1))
plotImageArray(recolored_img, main = "recolored image")
plotImageArray(viridis_img, main = "swapped centers")
```
You can also inspect the color palette on its own:
```{r, fig.asp=0.25, fig.width = 5}
# where we're going, we don't need figure margins!
par(mar = rep(0, 4))
# all colors the same size, with printed numbers for their index
plotColorPalette(centers = recolorize_defaults$centers)
# colors proportional to their region size in the image
plotColorPalette(centers = recolorize_defaults$centers,
sizes = recolorize_defaults$sizes)
```
### Clustering parameters
If you look at the documentation for the `recolorize` function, you'll see a lot of user-specifiable parameters. There are only really 3 major ones:
1. The clustering method (`method` argument)
2. The number of color clusters (`bins` and `n`)
3. The color space (`color_space`)
That said, the defaults work pretty well in most cases, and so long as you can see that you're not mushing together regions that should remain separate, most parameter combinations will work.
#### Clustering methods and number of color clusters
The two clustering methods in `recolorize` are color histogram binning (fast, consistent, and deterministic) and k-means clustering (comparatively slower and heuristic, but more intuitive). The `bins` argument is accessed by the `histogram` method, and `n` goes with the `kmeans` method. I highly recommend the histogram binning unless you have a good reason not to use it, but we'll go over them both. Before I explain them, let's do a quick comparison:
```{r, fig.height = 3}
# number of bins is ^3, so we'll specify 2 bins and 8 kmeans clusters to get 8 color centers either way:
hist_obj <- recolorize(corbetti, method = "histogram", bins = 2)
kmeans_obj <- recolorize(corbetti, method = "kmeans", n = 8)
```
For this image, both of these options do a pretty decent job at simplifying the image down to 8 colors, but there are substantial differences in their approaches.
To understand the differences, it helps to start by looking at all the pixels in the original image in a given color space. We'll use RGB for now, since most people are familiar with it:
```{r,message=FALSE, fig.width = 7, fig.height = 3}
# plot the pixels in the image in RGB color space:
library(colordistance)
layout(matrix(1:2, nrow = 1))
plotPixels(corbetti, angle = 30, main = "",
cex.lab = 0.5, cex.axis = 0.5,
mar = rep(2, 4))
plotPixels(corbetti, angle = -30, main = "",
cex.lab = 0.5, cex.axis = 0.5,
mar = rep(2, 4))
```
Each location represents a different color. So this step takes us from an overwhelming number of unique colors to just a few.
Histogram binning divides up this 3D color space into bins, then counts the number of pixels that fall into that bin and calculates their average color. The nice thing about this is that it's quite fast, since we're not really doing any clustering; the bins we assign the pixels to will be the same for every image, and we're not calculating the distances between the pixels and their assigned color. We're just checking which pixels fall into which region. The *really* nice thing is that it's deterministic, which means you get the same result every single time you run it. The downside is that makes this approach almost guaranteed to over-split colors, since your color regions will rarely fall cleanly within the boundaries of these bins, and many of the bins you end up with will be empty or have very few pixels. We can see this if we increase the number of bins per color channel:
```{r,message=FALSE, fig.width = 7.5, fig.height=3}
layout(matrix(1:3, nrow = 1))
# using increasing numbers of bins per channel:
for (i in 2:4) {
hist_fit <- recolorize(corbetti, method = "hist", bins = i, plotting = FALSE)
plotColorClusters(centers = hist_fit$centers,
sizes = hist_fit$sizes, scaling = 10,
tick.marks = F, xlab = "R", ylab = "G", zlab = "B",
main = paste(i, "bins per channel"))
}
```
Notice a couple of things: first, the number of bins increases as the cube of the `bins` argument (so 2, 3, 4 = 8, 27, and 64 bins). That's because we're dividing each of the R, G, and B color channels into that many bins. Second, even as we increase the number of bins, most of those bins are staying empty (or very small). Even with 64 color centers, we still end up with a few large ones and many tiny ones:
```{r}
plot(hist_fit, sizes = TRUE)
```
K-means clustering, on the other hand, is a well-known method for partitioning data into *n* clusters. You just provide the number of clusters you want, and it will try to find the best locations for them, where 'best' means minimizing the squared Euclidean distances between pixels and color centers within each cluster. A lot of color segmentation tools will *only* use k-means clustering (or a similar method), because it's relatively easy to implement and does produce good results if your images have clear color boundaries and very different colors (i.e. the pixels are far apart in color space). If you were going to stop at the initial clustering step, this would probably be a better option than the histogram binning for that reason. One issue if you're trying to process many images, though, is that you have to decide how many clusters you want for each one, and there's no clear criterion for selecting that value. It's also quite prone to splitting up major colors as you increase *n*, because that lowers the within-cluster variance more:
```{r, fig.width=7.5, fig.height = 4}
library(recolorize)
k_vec <- 3:10
layout(matrix(1:8, nrow = 2))
for (i in k_vec) {
kmeans_fit <- recolorize(corbetti, "k", n = i, plotting = FALSE)
plotColorClusters(centers = kmeans_fit$centers,
sizes = kmeans_fit$sizes, scaling = 10,
tick.marks = F,
xlab = "", ylab = "", zlab = "",
main = paste("n =", i),
mar = c(2, 1, 2, 1),
xlim = 0:1, ylim = 0:1, zlim = 0:1)
}
```
But the main issue with this method is that it's implemented heuristically, which means you're not guaranteed to get the same results every time you run it; and although you should get similar ones, you'll also get the color centers returned to you in a random order. We can see this by running the exact same k-means clustering code 3 times:
```{r, fig.width = 6, fig.height = 4}
kmeans_1 <- recolorize(corbetti, method = "k", n = 8, plotting = FALSE)
kmeans_2 <- recolorize(corbetti, method = "k", n = 8, plotting = FALSE)
kmeans_3 <- recolorize(corbetti, method = "k", n = 8, plotting = FALSE)
layout(matrix(1:6, nrow = 1), widths = c(rep(.25, 3),
rep(.25/3, 3)))
for (i in list(kmeans_1, kmeans_2, kmeans_3)) {
par(mar = rep(0, 4))
plotImageArray(i$recolored_img)
}
for (i in list(kmeans_1, kmeans_2, kmeans_3)) {
par(mar = rep(0, 4))
plotColorPalette(i$centers, i$sizes, horiz = FALSE)
}
```
The differences in the color maps are subtle (but noticeable), but notice especially the order of the colors in the color palettes on the right. More or less the same color centers pop up, but their index values don't match. If you run this code one day and pull out all the red clusters by their index, or merge the multiple green clusters, those values will change the next time you run the code. That and the need to specify cluster numbers for each image are more or less why I recommend not using this method unless you have a reason.
#### Color spaces
There is a lot to be said about color spaces, and most of it is complicated and requires a hefty dose of math. Check out [this vignette](https://cran.r-project.org/web/packages/colordistance/vignettes/color-spaces.html) for a quick overview of why they matter for color clustering. I'll go ahead and quote myself here:
> A mathematically defined color space maps perceived colors onto a system of coordinates. Because human beings have trichromatic color vision (cone cells that have peak sensitivities at red, green, and blue wavelengths), most color spaces are three-dimensional. The most familiar of these is probably RGB, or red-green-blue, the tri-channel system that most computers use to store and display color images; other common ones include HSV (hue, saturation, and value) and CMYK (cyan, magenta, yellow, and key).
>
> No color space is a perfect representation of color, and most of the existing ones are tuned specifically for standard human color vision. Different color spaces are usually designed to address some issues more than others. For example, RGB provides a computationally tractable storage format for images and is a decent representation of human color vision; this comes at the cost of displaying a smaller range of colors than human eyes can perceive. Color spaces that attempt to more closely mimic human color perception require additional information about lighting in a scene, and are shaped irregularly.
For our purposes, that means that the color space you choose to do your clustering in can have profound effects on your results, because it determines the Euclidean distances between different colors. For example, in RGB space, red and yellow are as far apart from each other as red and black, but black and yellow are farther apart than black and red are. That doesn't really line up with our perception, but it's how the color space is arranged. CIE Lab color space is specifically designed to mimic human color perception (so the Euclidean distances reflect perceived distances), but it's also a weird blob shape, so we usually need more initial partitions to separate out the colors. We can try out different color spaces:
```{r, fig.width = 6, fig.height = 2.5}
rgb_fit <- recolorize(corbetti, color_space = "sRGB", plotting = FALSE)
lab_fit <- recolorize(corbetti, color_space = "Lab", plotting = FALSE)
layout(matrix(1:4, nrow = 1), widths = c(.4, .1, .4, .1))
plotImageArray(rgb_fit$recolored_img, "RGB space")
plotColorPalette(rgb_fit$centers, rgb_fit$sizes)
plotImageArray(lab_fit$recolored_img, "CIE Lab space")
plotColorPalette(lab_fit$centers, lab_fit$sizes)
```
You may notice that for all I talked it up, the CIE Lab space option looks terrible. That's because unlike RGB space, CIE Lab colors aren't evenly distributed across a cube, so most of the different colors are in the center of the range. 2 bins per channel doesn't do a great job with splitting that up. We get much better results if we allow for more than 2 bins per channel:
```{r}
lab_fit_3 <- recolorize(corbetti, bins = 4, color_space = "Lab")
```
That said, I usually find myself using RGB space for the initial clustering step, and CIE Lab space for refining those results. One thing to note is that regardless of which color space you use for clustering, the `centers` matrix is *always in RGB color space*. That's because it's used for plotting.
I don't have much general guidance for how to choose between all of these parameters at this stage; I would recommend using histogram binning in RGB space, with as many bins as needed to separate out all of the different colors. But part of the reason I'm including more options than that is because it really does depend on the color distribution in your images. This *Chrysochroa corbetti* image, for example, is literally red, green, and blue; that makes RGB space pretty appropriate for a first pass!
It's convenient to use the same scheme for every image in your dataset, so you might end up using whatever values are needed for your most complex image and over-splitting most of your other images. That's usually fine, because the next set of steps will try to lump colors together or remove minor details. You want to be just granular enough to capture the details you care about, and it's okay if some colors are split up.
# Refining fits automatically and semi-automatically
# Overview of package functions
1. Functions that do the initial clustering (i.e. take a raw image).
2. Functions that automatically edit the initial clustering (i.e. refine an initial fit).
3. Functions that allow users to make manual-ish changes.
4. Functions to export to other packages.
# Worked example on a single image
corbetti! Go from initial problem
1. hey, 5 clusters? uhhh, 6? wait, why does this give me a different answer every time
2. too many clusters, but it looks good
3. refinement options: drop small clusters, recluster based on similarity, imposing colors
4. DIY options: manual layer editing, smushing clusters together
5. export options: well, you can save the image or export a single layer
as a bitmap, etc
# Worked example on a more complicated image
That shiny bastard, *Chrysochroa fulgidissima*
# Worked example on a batch of images
Just our Five Guys.
# Some considerations
### How do I choose a procedure?
Most things will more or less work; if it looks reasonable, it is.
Keep in mind that there is a big difference between getting slightly different color maps and getting qualitatively different results. Keep your final goal in mind. You can also try lots of different things and see if it makes a real difference. etc.
### How much does the color space matter?
Dude: a lot!
### What if my parameters work well for some images, but not others?
It does what it does, man. You can get way fancier with cutoffs than
I have here. This package is built on some pretty simple scaffolding:
you get a starting set of clusters, then you modify them. If you have a
better/more refined way of deciding which colors to cluster, then go
for it.
```{r, echo=FALSE,message=FALSE, fig.width=7, fig.height = 3.5, fig.cap="Pixels from the above image in RGB color space, viewed from two angles."}
library(colordistance)
layout(matrix(1:2, nrow = 1))
plotPixels(images[2], angle = 30, main = "", cex.lab = 0.5, cex.axis = 0.5)
plotPixels(images[2], angle = -30, main = "", cex.lab = 0.5, cex.axis = 0.5)
```
There's certainly a blob of green pixels in there, but they're not all the exact same color. In order to extract all the green pixels, we either have to specify a range of colors that we'll call 'green', or open up the original image in a image editing software like ImageJ or Photoshop and manually select the green region. You can probably see how this would start to get out of hand as you increase the number of images or the diversity of colors in a dataset, because we have to introduce more and more subjectivity, and most images will not have such clear boundaries between color patches.
This is pretty convenient and relatively lightweight. It also means we can swap the colors to whatever we like.
```{r, fig.width = 6, fig.height = 2.5}
rgb_fit <- recolorize(corbetti, color_space = "sRGB", plotting = FALSE)
lab_fit <- recolorize(corbetti, color_space = "Lab", plotting = FALSE)
layout(matrix(1:4, nrow = 1), widths = c(.4, .1, .4, .1))
par(mar = c(0, 2, 0, 0))
plotImageArray(rgb_fit$recolored_img, "RGB space")
plotColorPalette(rgb_fit$centers, rgb_fit$sizes)
plotImageArray(lab_fit$recolored_img, "CIE Lab space")
# bookkeeping
library(recolorize)
images <- dir(system.file("extdata/", package = "recolorize"), "png", full.names = TRUE)
img <- readImage(images[2])
# get fit
init_fit <- recolorize(img, plotting = FALSE)
re_fit <- recluster(init_fit, similarity_cutoff = 45, plot_final = FALSE)
re_fit <- recluster(init_fit, similarity_cutoff = 45, plot_final = FALSE)
# plot it
layout(matrix(1:3, nrow = 1), widths = c(0.45, 0.1, 0.45))
# plot it
layout(matrix(1:3, nrow = 1), widths = c(0.45, 0.1, 0.45))
par(mar = c(0, 0, 2, 0))
plotImageArray(re_fit$original_img, main = "Original")
plotColorPalette(re_fit$centers, re_fit$sizes, horiz = FALSE)
plotImageArray(re_fit$recolored_img, main = "Color map")
```{r, eval=F}
# get the path to the image (comes with the package, so we use system.file):
img <- system.file("extdata/corbetti.png", package = "recolorize")
# perform initial clustering:
init_fit <- recolorize(img)
# and refine:
re_fit <- recluster(init_fit, similarity_cutoff = 45)
layout(matrix(1:5, nrow = 1))
layers <- splitByColor(re_fit)
# define image path - we're using an image that comes with the package
img_path <- system.file("extdata/corbetti.png", package = "recolorize")
# load image
img <- readImage(img_path)
# it's just an array with 4 channels:
dim(img)
layout(matrix(1:5, nrow = 1))
plotImageArray(img, main = "RGB image")
plotImageArray(img[ , , 1], main = "R channel")
plotImageArray(img[ , , 2], main = "G channel")
plotImageArray(img[ , , 3], main = "B channel")
plotImageArray(img[ , , 4], main = "Alpha channel")
layout(matrix(1:5, nrow = 1))
plotImageArray(img, main = "RGB image")
plotImageArray(img[ , , 1], main = "R channel")
plotImageArray(img[ , , 2], main = "G channel")
plotImageArray(img[ , , 3], main = "B channel")
plotImageArray(img[ , , 4], main = "Alpha channel")
corbetti <- system.file("extdata/corbetti.png", package = "recolorize")
# using all the default parameters:
recolorize_defaults <- recolorize(img = corbetti)
# you can also read in the image as an array:
corbetti_array <- readImage(corbetti)
# and then pass it to the recolorize function
# (not plotting this time since it gives you identical results)
recolorize_defaults <- recolorize(img = corbetti_array, plotting = FALSE)
class(recolorize_defaults)
attributes(recolorize_defaults)
summary(recolorize_defaults)
dim(recolorize_defaults$recolored_img)
dim(recolorize_defaults$pixel_assignments)
# using just the pixel_assignments and centers to recreate the recolored image:
recolored_img <- constructImage(pixel_assignments = recolorize_defaults$pixel_assignments,
centers = recolorize_defaults$centers)
# we can also pass a different set of centers:
new_centers <- viridisLite::viridis(8)
new_centers <- t(col2rgb(new_centers) / 255)
viridis_img <- constructImage(pixel_assignments = recolorize_defaults$pixel_assignments,
centers = new_centers)
layout(matrix(1:2, nrow = 1))
plotImageArray(recolored_img, main = "recolored image")
plotImageArray(viridis_img, main = "swapped centers")
# where we're going, we don't need figure margins!
par(mar = rep(0, 4))
# all colors the same size, with printed numbers for their index
plotColorPalette(centers = recolorize_defaults$centers)
# colors proportional to their region size in the image
plotColorPalette(centers = recolorize_defaults$centers,
sizes = recolorize_defaults$sizes)
# where we're going, we don't need figure margins!
par(mar = rep(0, 4))
# all colors the same size, with printed numbers for their index
plotColorPalette(centers = recolorize_defaults$centers)
# number of bins is ^3, so we'll specify 2 bins and 8 kmeans clusters to get 8 color centers either way:
hist_obj <- recolorize(corbetti, method = "histogram", bins = 2)
kmeans_obj <- recolorize(corbetti, method = "kmeans", n = 8)
layout(matrix(1:3, nrow = 1))
# using increasing numbers of bins per channel:
for (i in 2:4) {
hist_fit <- recolorize(corbetti, method = "hist", bins = i, plotting = FALSE)
plotColorClusters(centers = hist_fit$centers,
sizes = hist_fit$sizes, scaling = 10,
tick.marks = F, xlab = "R", ylab = "G", zlab = "B",
main = paste(i, "bins per channel"))
}
plot(hist_fit, sizes = TRUE)
library(recolorize)
k_vec <- 3:10
layout(matrix(1:8, nrow = 2))
for (i in k_vec) {
kmeans_fit <- recolorize(corbetti, "k", n = i, plotting = FALSE)
plotColorClusters(centers = kmeans_fit$centers,
sizes = kmeans_fit$sizes, scaling = 10,
tick.marks = F,
xlab = "", ylab = "", zlab = "",
main = paste("n =", i),
mar = c(2, 1, 2, 1),
xlim = 0:1, ylim = 0:1, zlim = 0:1)
}
```{r, fig.width = 6, fig.height = 4}
kmeans_1 <- recolorize(corbetti, method = "k", n = 8, plotting = FALSE)
kmeans_2 <- recolorize(corbetti, method = "k", n = 8, plotting = FALSE)
kmeans_3 <- recolorize(corbetti, method = "k", n = 8, plotting = FALSE)
layout(matrix(1:6, nrow = 1), widths = c(rep(.25, 3),
rep(.25/3, 3)))
for (i in list(kmeans_1, kmeans_2, kmeans_3)) {
par(mar = rep(0, 4))
plotImageArray(i$recolored_img)
}
for (i in list(kmeans_1, kmeans_2, kmeans_3)) {
par(mar = rep(0, 4))
plotColorPalette(i$centers, i$sizes, horiz = FALSE)
}
# image path
corbetti <- system.file("extdata/corbetti.png", package = "recolorize")
# using default settings
init_fit <- recolorize(corbetti, method = "histogram", bins = 2, color_sapce = "sRGB")
# using default settings
init_fit <- recolorize(corbetti, method = "histogram", bins = 2, color_space = "sRGB")
recluster_fit <- recluster(init_fit, color_space = "Lab", similarity_cutoff = 60, plot_hclust = TRUE)
recluster_fit <- recluster(init_fit, color_space = "Lab", similarity_cutoff = 45, plot_hclust = TRUE)
threshold_fit <- thresholdRecolor(init_fit, pct = 0.05)
threshold_fit <- thresholdRecolor(init_fit, pct = 0.01)
# this isn't as effective
threshold_fit <- thresholdRecolor(init_fit, pct = 0.02)
init_fit <- recolorize(corbetti, method = "histogram", bins = 3, color_space = "sRGB")
# this isn't as effective
threshold_fit <- thresholdRecolor(init_fit, pct = 0.02)
# this isn't as effective
threshold_fit <- thresholdRecolor(init_fit, pct = 0.05)
# this isn't as effective
threshold_fit <- thresholdRecolor(init_fit, pct = 0.1)
# this isn't as effective
threshold_fit <- thresholdRecolor(init_fit, pct = 0.05)
plot(init_fit)
# using default settings
init_fit <- recolorize(corbetti, method = "histogram", bins = 2, color_space = "sRGB")
plot(init_fit)
merge_fit <- mergeLayers(init_fit, merge_list = list(1, 2,
c(3, 5),
c(4, 7),
c(6, 8)))
# we can clean/despeckle layers:
edited_fit <- editLayer(merge_fit, layer_idx = 1, operation = "clean", px_size = 2)
# we can clean/despeckle layers:
edited_fit <- editLayer(merge_fit, layer_idx = 1, operation = "fill", px_size = 2)
# we can clean/despeckle layers:
edited_fit <- editLayer(merge_fit, layer_idx = 1, operation = "shrink", px_size = 2)
# we can clean/despeckle layers:
edited_fit <- editLayer(merge_fit, layer_idx = 1, operation = "shrink", px_size = 3)
edited_fit2 <- editLayer(edited_fit, layer_idx = 1, operation = "grow", px_size = 2)
edited_fit2 <- editLayer(edited_fit, layer_idx = 1, operation = "grow", px_size = 3)
# we can clean/despeckle layers:
edited_fit <- editLayer(merge_fit, layer_idx = 1, operation = "clean", px_size = 3)
# we can clean/despeckle layers:
edited_fit <- editLayer(merge_fit, layer_idx = 1, operation = "clean", px_size = 2)
edited_fit2 <- editLayer(merge_fit, layer_idx = 1, operation = "fill", px_size = 2)
# we can do several layers at once:
edited_multiple <- editLayers(merge_fit)
# we can do several layers at once:
edited_multiple <- editLayers(merge_fit, operations = "shrink", px_sizes = 8)
# we can do several layers at once:
edited_multiple <- editLayers(merge_fit, operations = "shrink", px_sizes = 5)
# we can do several layers at once:
edited_multiple <- editLayers(merge_fit, operations = "clean", px_sizes = 5)
# we can do several layers at once:
edited_multiple <- editLayers(merge_fit, operations = "clean", px_sizes = 10)
dir(system.file("extdata", package = "recolorize"))
im1 <- system.file("extdata/ocellata.png", package = "recolorize")
im2 <- system.file("extdata/ephippigera.png", package = "recolorize")
fit_1 <- recolorize(im1)
fit_2 <- imposeColors(im2, centers = fit_1$centers)
fit_2 <- imposeColors(im2, centers = fit_1$centers, adjust_centers = FALSE)
rgb_centers <- col2rgb(c("red", "green", "blue",
"cyan", "magenta", "yellow",
"black", "white"))
rgb_centers
rgb_centers <- t(col2rgb(c("red", "green", "blue",
"cyan", "magenta", "yellow",
"black", "white")) / 255)
fit_rgb <- imposeColors(im2, centers = rgb_centers, adjust_centers = FALSE)
# image path
fulgidissima <- system.file("extdata/fulgidissima.png", package = "recolorize")
# load image
img <- readImage(fulgidissima)
# load image
img <- readImage(fulgidissima)
?blurImage
#
blurred_img <- blurImage(img, blur_function = "blur_anisotropic", 2)
#
blurred_img <- blurImage(img, blur_function = "blur_anisotropic", 5)
#
blurred_img <- blurImage(img, blur_function = "blur_anisotropic", amplitude = 5)
#
blurred_img <- blurImage(img, blur_function = "blur_anisotropic",
amplitude = 5, sharpness = 3)
#
blurred_img <- blurImage(img, blur_function = "blur_anisotropic",
amplitude = 1, sharpness = 3)
#
blurred_img <- blurImage(img, blur_function = "blur_anisotropic",
amplitude = 2, sharpness = 3)
#
blurred_img <- blurImage(img, blur_function = "blur_anisotropic",
amplitude = 2, sharpness = 1)
#
blurred_img <- blurImage(img, blur_function = "blur_anisotropic",
amplitude = 2, sharpness = 10)
#
blurred_img <- blurImage(img, blur_function = "medianblur",
n = 5, threshold = 0.5)
#
blurred_img <- blurImage(img, blur_function = "medianblur",
n = 5, threshold = 0.4)
#
blurred_img <- blurImage(img, blur_function = "medianblur",
n = 5, threshold = 0.2)
init_fit
recolorize_obj <- init_fit
pixel_idx <- which(recolorize_obj$pixel_assignments != 0)
pixel_idx
# get residuals in given color space
imDist(recluster_fit$original_img,
recluster_fit$recolored_img)
# get residuals in given color space
imDist(merge_fit$recolored_img,
recluster_fit$recolored_img)
# we can identify the hotspots of differences between two clustering methods:
imdist <- imDist(merge_fit$recolored_img,
recluster_fit$recolored_img)
# we can identify the hotspots of differences between two clustering methods:
fit_dist <- imDist(merge_fit$recolored_img,
recluster_fit$recolored_img)
hist(fit_dist)
hist(fit_dist > 0)
hist(fit_dist[which(fit_dist > 0)])
# or between the original image and the color map:
im_dist <- imDist(merge_fit$original_img,
merge_fit$recolored_img)
?imDist
# we can identify the hotspots of differences between two clustering methods:
fit_dist <- imDist(merge_fit$recolored_img,
recluster_fit$recolored_img)
# or between the original image and the color map:
im_dist <- imDist(merge_fit$original_img,
merge_fit$recolored_img)
hist(im_dist)
# we can see how our residuals are distributed:
hist(sqrt(im_dist^2))
# we can see how our residuals are distributed:
hist(sqrt(im_dist^2))
# and we can split by color
layers <- splitByColor(merge_fit, plot_method = "binary")
# and we can split by color
layout(matrix(1:5, nrow = 1))
layers <- splitByColor(merge_fit, plot_method = "binary")
layers <- splitByColor(merge_fit, plot_method = "colormask")
layers <- splitByColor(merge_fit, plot_method = "binary")
as_classify <- classify_recolorize(recluster_fit)
devtools::load_all(".")
# we can see how our residuals are distributed:
hist(im_dist, main = "CIE Lab distances")
as_classify <- classify_recolorize(recluster_fit)
classify_obj <- classify_recolorize(recluster_fit)
test <- pavo::adjacent(classify_obj)
test <- pavo::adjacent(classify_obj, xscale = 10)
